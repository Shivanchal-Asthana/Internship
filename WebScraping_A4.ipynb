{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8945536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import selenium\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Importing requests\n",
    "import requests\n",
    "\n",
    "#importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "# Importing required Exceptions which needs to handled\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementNotInteractableException\n",
    "\n",
    "import re\n",
    "\n",
    "#import plotty\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e79d9733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "PATH = 'C:/Users/hp-pc/Downloads/chromedriver_win32/chromedriver'\n",
    "driver = webdriver.Chrome(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab9bb61",
   "metadata": {},
   "source": [
    "Q1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "\n",
    "You need to find following details:\n",
    "1. Rank\n",
    "2. Name\n",
    "3. Artist\n",
    "4. Upload date\n",
    "5. Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e370a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'  \n",
    "driver.get(url) #Opening the Wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ad54cc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video_Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload_Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>9.98</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>7.70</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>6.09</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.58</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.38</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.84</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.55</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.48</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.42</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>4.40</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.30</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>3.79</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.62</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.50</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.50</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.48</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.48</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.39</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.21</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.21</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.20</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>3.17</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.15</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.15</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.15</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>Shake It Off</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3.13</td>\n",
       "      <td>August 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.06</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.06</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.03</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>Mi Gente</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>3.02</td>\n",
       "      <td>June 29, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                 Video_Name  \\\n",
       "0    1.                           Baby Shark Dance   \n",
       "1    2.                                  Despacito   \n",
       "2    3.                       Johny Johny Yes Papa   \n",
       "3    4.                               Shape of You   \n",
       "4    5.                              See You Again   \n",
       "5    6.                                  Bath Song   \n",
       "6    7.  Learning Colors – Colorful Eggs on a Farm   \n",
       "7    8.   Masha and the Bear – Recipe for Disaster   \n",
       "8    9.                                Uptown Funk   \n",
       "9   10.                Phonics Song with Two Words   \n",
       "10  11.                              Gangnam Style   \n",
       "11  12.                             Dame Tu Cosita   \n",
       "12  13.                                      Sugar   \n",
       "13  14.                                      Sorry   \n",
       "14  15.                                       Roar   \n",
       "15  16.                          Wheels on the Bus   \n",
       "16  17.                             Counting Stars   \n",
       "17  18.                          Thinking Out Loud   \n",
       "18  19.                             Girls Like You   \n",
       "19  20.                                      Faded   \n",
       "20  21.                                 Dark Horse   \n",
       "21  22.                                     Axel F   \n",
       "22  23.                                 Let Her Go   \n",
       "23  24.                                   Bailando   \n",
       "24  25.                                    Lean On   \n",
       "25  26.                               Shake It Off   \n",
       "26  27.                        Baa Baa Black Sheep   \n",
       "27  28.                                    Perfect   \n",
       "28  29.           Waka Waka (This Time for Africa)   \n",
       "29  30.                                   Mi Gente   \n",
       "\n",
       "                                         Artist Upload_Date              Views  \n",
       "0   Pinkfong Baby Shark - Kids' Songs & Stories        9.98      June 17, 2016  \n",
       "1                                    Luis Fonsi        7.70   January 12, 2017  \n",
       "2                                   LooLoo Kids        6.09    October 8, 2016  \n",
       "3                                    Ed Sheeran        5.58   January 30, 2017  \n",
       "4                                   Wiz Khalifa        5.38      April 6, 2015  \n",
       "5                    Cocomelon – Nursery Rhymes        4.84        May 2, 2018  \n",
       "6                                   Miroshka TV        4.55  February 27, 2018  \n",
       "7                                    Get Movies        4.48   January 31, 2012  \n",
       "8                                   Mark Ronson        4.42  November 19, 2014  \n",
       "9                                     ChuChu TV        4.40      March 6, 2014  \n",
       "10                                          Psy        4.30      July 15, 2012  \n",
       "11                                    El Chombo        3.79      April 5, 2018  \n",
       "12                                     Maroon 5        3.62   January 14, 2015  \n",
       "13                                Justin Bieber        3.50   October 22, 2015  \n",
       "14                                   Katy Perry        3.50  September 5, 2013  \n",
       "15                   Cocomelon – Nursery Rhymes        3.48       May 24, 2018  \n",
       "16                                  OneRepublic        3.48       May 31, 2013  \n",
       "17                                   Ed Sheeran        3.39    October 7, 2014  \n",
       "18                                     Maroon 5        3.21       May 31, 2018  \n",
       "19                                  Alan Walker        3.21   December 3, 2015  \n",
       "20                                   Katy Perry        3.20  February 20, 2014  \n",
       "21                                   Crazy Frog        3.17      June 16, 2009  \n",
       "22                                    Passenger        3.15      July 25, 2012  \n",
       "23                             Enrique Iglesias        3.15     April 11, 2014  \n",
       "24                                  Major Lazer        3.15     March 22, 2015  \n",
       "25                                 Taylor Swift        3.13    August 18, 2014  \n",
       "26                   Cocomelon – Nursery Rhymes        3.06      June 25, 2018  \n",
       "27                                   Ed Sheeran        3.06   November 9, 2017  \n",
       "28                                      Shakira        3.03       June 4, 2010  \n",
       "29                                     J Balvin        3.02      June 29, 2017  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Empty List\n",
    "Rank=[]\n",
    "Video_Name=[]\n",
    "Artist=[]\n",
    "Upload_Date=[]\n",
    "Views=[]\n",
    "#Extracting rank from xpath\n",
    "try:\n",
    "    rank=driver.find_elements_by_xpath(\"//div[@class='mw-parser-output']//table[3]//tbody//tr//td[1]\")\n",
    "    for i in rank:\n",
    "        Rank.append(i.text)\n",
    "except:\n",
    "    Rank.append('-')\n",
    "#Extracting Video name from xpath\n",
    "try:\n",
    "    name=driver.find_elements_by_xpath(\"//div[@class='mw-parser-output']//table[3]//tbody//tr//td[2]\")\n",
    "    for i in name:\n",
    "        Video_Name.append(i.text.split('[').pop(0).replace(\"\\\"\",\"\"))\n",
    "except:\n",
    "    Video_Name.append('-')\n",
    "#Extracting Artist from xpath\n",
    "try:\n",
    "    artist=driver.find_elements_by_xpath(\"//div[@class='mw-parser-output']//table[3]//tbody//tr//td[3]\")\n",
    "    for i in artist:\n",
    "        Artist.append(i.text)\n",
    "except:\n",
    "    Artist.append('-')\n",
    "#Extracting Upload Date from xpath    \n",
    "try:\n",
    "    date=driver.find_elements_by_xpath(\"//div[@class='mw-parser-output']//table[3]//tbody//tr//td[4]\")\n",
    "    for i in date:\n",
    "        Upload_Date.append(i.text)\n",
    "except:\n",
    "    Upload_Date.append('-')\n",
    "#Extracting Views from xpath   \n",
    "try:\n",
    "    views=driver.find_elements_by_xpath(\"//div[@class='mw-parser-output']//table[3]//tbody//tr//td[5]\")\n",
    "    for i in views:\n",
    "        Views.append(i.text)\n",
    "except:\n",
    "    Views.append('-')\n",
    "    \n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Rank': Rank,\n",
    "                'Video_Name':Video_Name,\n",
    "                 'Artist': Artist,\n",
    "                 'Upload_Date': Upload_Date,\n",
    "                 'Views': Views,\n",
    "                })\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feeb863",
   "metadata": {},
   "source": [
    "Q2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "\n",
    "You need to find following details:\n",
    "1. Match title (I.e. 1st ODI)\n",
    "2. Series\n",
    "3. Place\n",
    "4. Date\n",
    "5. Time\n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd70ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.bcci.tv/'  #Opening the bcci.tv\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5) #time delay of 5 seconds\n",
    "\n",
    "clk_international = driver.find_element_by_xpath(\"/html/body/nav/div/div[2]/ul[1]/li[2]/a\") \n",
    "clk_international.click() #clicking International button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f132b958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA TEST SERIES 2021-22</td>\n",
       "      <td>Newlands, Cape Town</td>\n",
       "      <td>11 JAN 2022</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA ODI SERIES 2021/22</td>\n",
       "      <td>Boland Park, Paarl</td>\n",
       "      <td>19 JAN 2022</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA ODI SERIES 2021/22</td>\n",
       "      <td>Boland Park, Paarl</td>\n",
       "      <td>21 JAN 2022</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>INDIA TOUR OF SOUTH AFRICA ODI SERIES 2021/22</td>\n",
       "      <td>Newlands, Cape Town</td>\n",
       "      <td>23 JAN 2022</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>WEST INDIES TOUR OF INDIA ODI SERIES 2022</td>\n",
       "      <td>NARENDRA MODI STADIUM, Ahmedabad</td>\n",
       "      <td>6 FEB 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>WEST INDIES TOUR OF INDIA ODI SERIES 2022</td>\n",
       "      <td>Sawai Mansingh Stadium, Jaipur</td>\n",
       "      <td>9 FEB 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>WEST INDIES TOUR OF INDIA ODI SERIES 2022</td>\n",
       "      <td>Eden Gardens, Kolkata</td>\n",
       "      <td>12 FEB 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>WEST INDIES TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Barabati Stadium, Cuttack</td>\n",
       "      <td>15 FEB 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>WEST INDIES TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Dr YS Rajasekhara Reddy ACA</td>\n",
       "      <td>18 FEB 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>WEST INDIES TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Greenfield International Stadium, Thiruvanant...</td>\n",
       "      <td>20 FEB 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA TEST SERIES 2022</td>\n",
       "      <td>M Chinnaswamy Stadium, Bengaluru</td>\n",
       "      <td>25 FEB 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA TEST SERIES 2022</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium,...</td>\n",
       "      <td>5 MAR 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium,...</td>\n",
       "      <td>13 MAR 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium,...</td>\n",
       "      <td>15 MAR 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Bharat Ratna Shri Atal Bihari Vajpayee Ekana ...</td>\n",
       "      <td>18 MAR 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>MA Chidambaram Stadium, Chennai</td>\n",
       "      <td>9 JUN 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>M Chinnaswamy Stadium, Bengaluru</td>\n",
       "      <td>12 JUN 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Vidarbha Cricket Association Stadium, Nagpur</td>\n",
       "      <td>14 JUN 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4th T20I</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Saurashtra Cricket Association Stadium, Rajkot</td>\n",
       "      <td>17 JUN 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5th T20I</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Arun Jaitley Stadium, Delhi</td>\n",
       "      <td>19 JUN 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match_Title                                          Series  \\\n",
       "0    3rd Test   INDIA TOUR OF SOUTH AFRICA TEST SERIES 2021-22   \n",
       "1     1st ODI    INDIA TOUR OF SOUTH AFRICA ODI SERIES 2021/22   \n",
       "2     2nd ODI    INDIA TOUR OF SOUTH AFRICA ODI SERIES 2021/22   \n",
       "3     3rd ODI    INDIA TOUR OF SOUTH AFRICA ODI SERIES 2021/22   \n",
       "4     1st ODI        WEST INDIES TOUR OF INDIA ODI SERIES 2022   \n",
       "5     2nd ODI        WEST INDIES TOUR OF INDIA ODI SERIES 2022   \n",
       "6     3rd ODI        WEST INDIES TOUR OF INDIA ODI SERIES 2022   \n",
       "7    1st T20I        WEST INDIES TOUR OF INDIA T20 SERIES 2022   \n",
       "8    2nd T20I        WEST INDIES TOUR OF INDIA T20 SERIES 2022   \n",
       "9    3rd T20I        WEST INDIES TOUR OF INDIA T20 SERIES 2022   \n",
       "10   1st Test         SRI LANKA TOUR OF INDIA TEST SERIES 2022   \n",
       "11   2nd Test         SRI LANKA TOUR OF INDIA TEST SERIES 2022   \n",
       "12   1st T20I          SRI LANKA TOUR OF INDIA T20 SERIES 2022   \n",
       "13   2nd T20I          SRI LANKA TOUR OF INDIA T20 SERIES 2022   \n",
       "14   3rd T20I          SRI LANKA TOUR OF INDIA T20 SERIES 2022   \n",
       "15   1st T20I       SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "16   2nd T20I       SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "17   3rd T20I       SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "18   4th T20I       SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "19   5th T20I       SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "\n",
       "                                                Place         Date  \\\n",
       "0                                 Newlands, Cape Town  11 JAN 2022   \n",
       "1                                  Boland Park, Paarl  19 JAN 2022   \n",
       "2                                  Boland Park, Paarl  21 JAN 2022   \n",
       "3                                 Newlands, Cape Town  23 JAN 2022   \n",
       "4                    NARENDRA MODI STADIUM, Ahmedabad   6 FEB 2022   \n",
       "5                      Sawai Mansingh Stadium, Jaipur   9 FEB 2022   \n",
       "6                               Eden Gardens, Kolkata  12 FEB 2022   \n",
       "7                           Barabati Stadium, Cuttack  15 FEB 2022   \n",
       "8                         Dr YS Rajasekhara Reddy ACA  18 FEB 2022   \n",
       "9    Greenfield International Stadium, Thiruvanant...  20 FEB 2022   \n",
       "10                   M Chinnaswamy Stadium, Bengaluru  25 FEB 2022   \n",
       "11   Punjab Cricket Association IS Bindra Stadium,...   5 MAR 2022   \n",
       "12   Punjab Cricket Association IS Bindra Stadium,...  13 MAR 2022   \n",
       "13   Himachal Pradesh Cricket Association Stadium,...  15 MAR 2022   \n",
       "14   Bharat Ratna Shri Atal Bihari Vajpayee Ekana ...  18 MAR 2022   \n",
       "15                    MA Chidambaram Stadium, Chennai   9 JUN 2022   \n",
       "16                   M Chinnaswamy Stadium, Bengaluru  12 JUN 2022   \n",
       "17       Vidarbha Cricket Association Stadium, Nagpur  14 JUN 2022   \n",
       "18     Saurashtra Cricket Association Stadium, Rajkot  17 JUN 2022   \n",
       "19                        Arun Jaitley Stadium, Delhi  19 JUN 2022   \n",
       "\n",
       "           Time  \n",
       "0   2:00 PM IST  \n",
       "1   2:00 PM IST  \n",
       "2   2:00 PM IST  \n",
       "3   2:00 PM IST  \n",
       "4   9:30 AM IST  \n",
       "5   9:30 AM IST  \n",
       "6   9:30 AM IST  \n",
       "7   7:30 PM IST  \n",
       "8   7:30 PM IST  \n",
       "9   7:30 PM IST  \n",
       "10  9:30 AM IST  \n",
       "11  9:30 AM IST  \n",
       "12  7:30 PM IST  \n",
       "13  7:30 PM IST  \n",
       "14  7:30 PM IST  \n",
       "15  7:30 PM IST  \n",
       "16  7:30 PM IST  \n",
       "17  7:30 PM IST  \n",
       "18  7:30 PM IST  \n",
       "19  7:30 PM IST  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating empty list\n",
    "match_title=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "\n",
    "#Extracting Match title by using xpath\n",
    "title=driver.find_elements_by_xpath(\"//*[@class='fix-place ng-binding ng-scope']\")\n",
    "for i in title:\n",
    "    match_title.append(i.text.split('-').pop(0))\n",
    "#Extracting series by using xpath \n",
    "series=driver.find_elements_by_xpath(\"//*[@class='fixture-card-top']//h5[2]\")\n",
    "for i in series:\n",
    "    Series.append(i.text)\n",
    "#Extracting place by using xpath\n",
    "place=driver.find_elements_by_xpath(\"//*[@class='fix-place ng-binding ng-scope']\")\n",
    "for i in place:\n",
    "    Place.append(i.text.split('-').pop(1))\n",
    "#Extracting Date by using xpath   \n",
    "date=driver.find_elements_by_xpath(\"//*[@class='ng-binding']//..//h5\")\n",
    "for i in date:\n",
    "    Date.append(i.text)\n",
    "#Extracting Time by using xpath   \n",
    "time=driver.find_elements_by_xpath(\"//*[@class='text-right ng-binding']//..//h5\")\n",
    "for i in time:\n",
    "    Time.append(i.text)\n",
    "    \n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Match_Title':match_title,\n",
    "                'Series':Series,\n",
    "                'Place':Place,\n",
    "                'Date': Date,\n",
    "                'Time': Time,\n",
    "                })\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1c0b35",
   "metadata": {},
   "source": [
    "Q3- Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "\n",
    "You need to find following details:\n",
    "1. Name\n",
    "2. Description\n",
    "\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2f1a41c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.guru99.com/'  #Opening the guru99.com\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5) #time delay of 5 seconds\n",
    "\n",
    "clk_testing = driver.find_element_by_xpath(\"/html/body/div[1]/header/div[1]/div/div/div/div/div/div/div/div[2]/div[1]/nav/div/ul/li[2]/a/span\")\n",
    "clk_testing.click() #clicking testing button\n",
    "\n",
    "time.sleep(3) #time delay of 3 seconds\n",
    "\n",
    "clk_selenium = driver.find_element_by_xpath(\"/html/body/div[1]/header/div[1]/div/div/div/div/div/div/div/div[2]/div[1]/nav/div/ul/li[2]/ul/li[12]/a\") \n",
    "clk_selenium.click() #clicking selenium button\n",
    "\n",
    "time.sleep(3) #time delay of 3 seconds\n",
    "\n",
    "clk_tutorial = driver.find_element_by_xpath(\"/html/body/div[1]/div/div/div/main/div/article/div/div/table[5]/tbody/tr[34]/td[1]/a\") \n",
    "clk_tutorial.click() #clicking tutorial button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b9120a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exception_Name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firefo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidElementStateExceptio</td>\n",
       "      <td>It occurs when command can’t be finished when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>It occurs when you afford to get the session w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExcep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an alert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver does n’t sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Exception_Name  \\\n",
       "0            ElementNotVisibleException   \n",
       "1         ElementNotSelectableException   \n",
       "2                NoSuchElementException   \n",
       "3                  NoSuchFrameException   \n",
       "4               NoAlertPresentException   \n",
       "5                 NoSuchWindowException   \n",
       "6        StaleElementReferenceException   \n",
       "7              SessionNotFoundException   \n",
       "8                      TimeoutException   \n",
       "9                    WebDriverException   \n",
       "10            ConnectionClosedException   \n",
       "11     ElementClickInterceptedException   \n",
       "12      ElementNotInteractableException   \n",
       "13             ErrorInResponseException   \n",
       "14  ErrorHandler.UnknownServerException   \n",
       "15         ImeActivationFailedException   \n",
       "16             ImeNotAvailableException   \n",
       "17         InsecureCertificateException   \n",
       "18             InvalidArgumentException   \n",
       "19         InvalidCookieDomainException   \n",
       "20          InvalidCoordinatesException   \n",
       "21          InvalidElementStateExceptio   \n",
       "22            InvalidSessionIdException   \n",
       "23       InvalidSwitchToTargetException   \n",
       "24                  JavascriptException   \n",
       "25                        JsonException   \n",
       "26             NoSuchAttributeException   \n",
       "27       MoveTargetOutOfBoundsException   \n",
       "28               NoSuchContextException   \n",
       "29                NoSuchCookieException   \n",
       "30                    NotFoundException   \n",
       "31          RemoteDriverServerException   \n",
       "32                  ScreenshotException   \n",
       "33           SessionNotCreatedException   \n",
       "34           UnableToSetCookieException   \n",
       "35           UnexpectedTagNameException   \n",
       "36              UnhandledAlertException   \n",
       "37      UnexpectedAlertPresentException   \n",
       "38               UnknownMethodException   \n",
       "39          UnreachableBrowserException   \n",
       "40          UnsupportedCommandException   \n",
       "\n",
       "                                          Description  \n",
       "0   This type of Selenium exception occurs when an...  \n",
       "1   This Selenium exception occurs when an element...  \n",
       "2   This Exception occurs if an element could not ...  \n",
       "3   This Exception occurs if the frame target to b...  \n",
       "4   This Exception occurs when you switch to no pr...  \n",
       "5   This Exception occurs if the window target to ...  \n",
       "6   This Selenium exception occurs happens when th...  \n",
       "7   The WebDriver is acting after you quit the bro...  \n",
       "8   Thrown when there is not enough time for a com...  \n",
       "9   This Exception takes place when the WebDriver ...  \n",
       "10  This type of Exception takes place when there ...  \n",
       "11  The command may not be completed as the elemen...  \n",
       "12  This Selenium exception is thrown when any ele...  \n",
       "13  This happens while interacting with the Firefo...  \n",
       "14  Exception is used as a placeholder in case if ...  \n",
       "15  This expectation will occur when IME engine ac...  \n",
       "16    It takes place when IME support is unavailable.  \n",
       "17  Navigation made the user agent to hit a certif...  \n",
       "18  It occurs when an argument does not belong to ...  \n",
       "19  This happens when you try to add a cookie unde...  \n",
       "20  This type of Exception matches an interacting ...  \n",
       "21  It occurs when command can’t be finished when ...  \n",
       "22  This Exception took place when the given sessi...  \n",
       "23  This occurs when the frame or window target to...  \n",
       "24  This issue occurs while executing JavaScript g...  \n",
       "25  It occurs when you afford to get the session w...  \n",
       "26  This kind of Exception occurs when the attribu...  \n",
       "27  It takes place if the target provided to the A...  \n",
       "28           ContextAware does mobile device testing.  \n",
       "29  This Exception occurs when no cookie matching ...  \n",
       "30  This Exception is a subclass of WebDriverExcep...  \n",
       "31  This Selenium exception is thrown when the ser...  \n",
       "32            It is not possible to capture a screen.  \n",
       "33  It happens when a new session could not be suc...  \n",
       "34  This occurs if a driver is unable to set a coo...  \n",
       "35  Happens if a support class did not get a web e...  \n",
       "36  This expectation occurs when there is an alert...  \n",
       "37  It occurs when there is the appearance of an u...  \n",
       "38  This Exception happens when the requested comm...  \n",
       "39  This Exception occurs only when the browser is...  \n",
       "40  This occurs when remote WebDriver does n’t sen...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Empty List\n",
    "Exception_name=[]\n",
    "Description=[]\n",
    "\n",
    "try:   # Extracting Exception_name from the xpath\n",
    "    name=driver.find_elements_by_xpath('//*[@class=\"table table-striped\"]//tr//td[1]')\n",
    "    for i in name:\n",
    "        Exception_name.append(i.text)\n",
    "except:\n",
    "    Exception_name.append('-')\n",
    "\n",
    "try:   # Extracting Description from the xpath\n",
    "    description=driver.find_elements_by_xpath('//*[@class=\"table table-striped\"]//tr//td[2]')\n",
    "    for i in description:\n",
    "        Description.append(i.text)\n",
    "except:\n",
    "    Description.append('-')\n",
    "    \n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Exception_Name': Exception_name,\n",
    "                'Description': Description,\n",
    "                })\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0952ae",
   "metadata": {},
   "source": [
    "Q4- Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "\n",
    "You have to find following details:\n",
    "1. Rank\n",
    "2. State\n",
    "3. GSDP\n",
    "4. GSDP\n",
    "5. Share\n",
    "6. GDP($ billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6de1471c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://statisticstimes.com/'  #Opening the statistics.com website\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5) #time delay of 5 seconds\n",
    "\n",
    "clk_eco = driver.find_element_by_xpath(\"//button[@class='dropbtn']//..//..//div[2]//button\")\n",
    "clk_eco.click()#clicking Economy button\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "clk_india = driver.find_element_by_xpath(\"//div[@class='dropdown-content']//..//..//div[2]//div//a[3]\") \n",
    "clk_india.click()#clicking India button\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "clk_stateGDP = driver.find_element_by_xpath(\"//a[@class='ec']//..//..//..//..//div[2]//ul//li[1]//a[1]\") \n",
    "clk_stateGDP.click()#clicking StateGDP button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5362a18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP19-20</th>\n",
       "      <th>GSDP18-19</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State  GSDP19-20  GSDP18-19   Share      GDP\n",
       "0     1                Maharashtra          -  2,632,792  13.94%  399.921\n",
       "1     2                 Tamil Nadu  1,845,853  1,630,208   8.63%  247.629\n",
       "2     3              Uttar Pradesh  1,687,818  1,584,764   8.39%  240.726\n",
       "3     4                    Gujarat          -  1,502,899   7.96%  228.290\n",
       "4     5                  Karnataka  1,631,977  1,493,127   7.91%  226.806\n",
       "5     6                West Bengal  1,253,832  1,089,898   5.77%  165.556\n",
       "6     7                  Rajasthan  1,020,989    942,586   4.99%  143.179\n",
       "7     8             Andhra Pradesh    972,782    862,957   4.57%  131.083\n",
       "8     9                  Telangana    969,604    861,031   4.56%  130.791\n",
       "9    10             Madhya Pradesh    906,672    809,592   4.29%  122.977\n",
       "10   11                     Kerala          -    781,653   4.14%  118.733\n",
       "11   12                      Delhi    856,112    774,870   4.10%  117.703\n",
       "12   13                    Haryana    831,610    734,163   3.89%  111.519\n",
       "13   14                      Bihar    611,804    530,363   2.81%   80.562\n",
       "14   15                     Punjab    574,760    526,376   2.79%   79.957\n",
       "15   16                     Odisha    521,275    487,805   2.58%   74.098\n",
       "16   17                      Assam          -    315,881   1.67%   47.982\n",
       "17   18               Chhattisgarh    329,180    304,063   1.61%   46.187\n",
       "18   19                  Jharkhand    328,598    297,204   1.57%   45.145\n",
       "19   20                Uttarakhand          -    245,895   1.30%   37.351\n",
       "20   21            Jammu & Kashmir          -    155,956   0.83%   23.690\n",
       "21   22           Himachal Pradesh    165,472    153,845   0.81%   23.369\n",
       "22   23                        Goa     80,449     73,170   0.39%   11.115\n",
       "23   24                    Tripura     55,984     49,845   0.26%    7.571\n",
       "24   25                 Chandigarh          -     42,114   0.22%    6.397\n",
       "25   26                 Puducherry     38,253     34,433   0.18%    5.230\n",
       "26   27                  Meghalaya     36,572     33,481   0.18%    5.086\n",
       "27   28                     Sikkim     32,496     28,723   0.15%    4.363\n",
       "28   29                    Manipur     31,790     27,870   0.15%    4.233\n",
       "29   30                   Nagaland          -     27,283   0.14%    4.144\n",
       "30   31          Arunachal Pradesh          -     24,603   0.13%    3.737\n",
       "31   32                    Mizoram     26,503     22,287   0.12%    3.385\n",
       "32   33  Andaman & Nicobar Islands          -          -       -        -"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#empty list\n",
    "rank=[]\n",
    "state=[]\n",
    "GSDP1=[]\n",
    "GSDP2=[]\n",
    "share=[]\n",
    "GDP=[]\n",
    "urls=[]\n",
    "\n",
    "\n",
    "try:   # Extracting rank from the xpath\n",
    "    ranks=driver.find_elements_by_xpath('//*[@id=\"table_id\"]//tbody//tr//td[1]')\n",
    "    for i in ranks:\n",
    "        rank.append(i.text)\n",
    "except:\n",
    "    rank.append('-')\n",
    "\n",
    "\n",
    "try:  # Extracting state from the xpath\n",
    "    states=driver.find_elements_by_xpath('//*[@id=\"table_id\"]//tbody//tr//td[2]')\n",
    "    for i in states:\n",
    "        state.append(i.text)\n",
    "except:\n",
    "    state.append('-')\n",
    "\n",
    "\n",
    "try:   # Extracting gsdp1 from the xpath\n",
    "    gsdp1=driver.find_elements_by_xpath('//*[@id=\"table_id\"]//tbody//tr//td[3]')\n",
    "    for i in gsdp1:\n",
    "        GSDP1.append(i.text)\n",
    "except:\n",
    "    GSDP1.append('-')\n",
    "\n",
    "try:   # Extracting gsdp2 from the xpath\n",
    "    gsdp2=driver.find_elements_by_xpath('//*[@id=\"table_id\"]//tbody//tr//td[4]')\n",
    "    for i in gsdp2:\n",
    "        GSDP2.append(i.text)\n",
    "except:\n",
    "    GSDP2.append('-')\n",
    "\n",
    "try:   # Extracting share from the xpath\n",
    "    shares=driver.find_elements_by_xpath('//*[@id=\"table_id\"]//tbody//tr//td[5]')\n",
    "    for i in shares:\n",
    "        share.append(i.text)\n",
    "except:\n",
    "    share.append('-')\n",
    "\n",
    "\n",
    "try:    # Extracting GDP from the xpath\n",
    "    gdp=driver.find_elements_by_xpath('//*[@id=\"table_id\"]//tbody//tr//td[6]')\n",
    "    for i in gdp:\n",
    "        GDP.append(i.text)\n",
    "except:\n",
    "    GDP.append('-')\n",
    "\n",
    "\n",
    "\n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Rank':rank,\n",
    "                'State':state,\n",
    "                'GSDP19-20':GSDP1,\n",
    "                'GSDP18-19': GSDP2,\n",
    "                'Share': share,\n",
    "                'GDP':GDP})\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fc9152",
   "metadata": {},
   "source": [
    "Q5- Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "\n",
    "You have to find the following details:\n",
    "1. Repository title\n",
    "2. Repository description\n",
    "3. Contributors count\n",
    "4. Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "987cda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/' #Opening the Github.com\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5) #Delay time of 5 seconds\n",
    "try:\n",
    "    clk_explore = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary\")\n",
    "    clk_explore.click() #Click on Explore option\n",
    "except:\n",
    "    clk_explore = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary\")\n",
    "    clk_explore.click() #Click on Explore option\n",
    "    \n",
    "time.sleep(2) #Delay time for 2 seconds\n",
    "\n",
    "clk_trending = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul/li[5]/a\")\n",
    "clk_trending.click() #click on trending button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03405561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping URL =  https://github.com/v4d1/SpoofThatMail\n",
      "Scraping URL =  https://github.com/windowjs/windowjs\n",
      "Scraping URL =  https://github.com/withastro/astro\n",
      "Scraping URL =  https://github.com/CyC2018/CS-Notes\n",
      "Scraping URL =  https://github.com/apache/superset\n",
      "Scraping URL =  https://github.com/eugeneyan/applied-ml\n",
      "Scraping URL =  https://github.com/cyrildiagne/ar-cutpaste\n",
      "Scraping URL =  https://github.com/abigsoft/jdog202201\n",
      "Scraping URL =  https://github.com/sottlmarek/DevSecOps\n",
      "Scraping URL =  https://github.com/facebookresearch/ConvNeXt\n",
      "Scraping URL =  https://github.com/input-output-hk/plutus-apps\n",
      "Scraping URL =  https://github.com/crater-invoice/crater\n",
      "Scraping URL =  https://github.com/MoienTajik/AspNetCore-Developer-Roadmap\n",
      "Scraping URL =  https://github.com/windowtoolbox/powershell-windows-toolbox\n",
      "Scraping URL =  https://github.com/commit-live-students/Data_Science_Masters_Program_2021\n",
      "Scraping URL =  https://github.com/itcharge/LeetCode-Py\n",
      "Scraping URL =  https://github.com/ethereumbook/ethereumbook\n",
      "Scraping URL =  https://github.com/synercys/annotated_latex_equations\n",
      "Scraping URL =  https://github.com/google/leveldb\n",
      "Scraping URL =  https://github.com/ultralytics/yolov5\n",
      "Scraping URL =  https://github.com/input-output-hk/plutus-pioneer-program\n",
      "Scraping URL =  https://github.com/files-community/Files\n",
      "Scraping URL =  https://github.com/alyssaxuu/omni\n",
      "Scraping URL =  https://github.com/QSCTech/zju-icicles\n",
      "Scraping URL =  https://github.com/prabhatsharma/zinc\n"
     ]
    }
   ],
   "source": [
    "urls1=[]\n",
    "urls2=[]\n",
    "urls = driver.find_elements_by_xpath(\"/html/body/div[4]/main/div[3]/div/div[2]/article/h1/a\")\n",
    "for url in urls:\n",
    "    urls1.append(url.get_attribute(\"href\"))\n",
    "\n",
    "#Creating Empty list\n",
    "Repository_title = []\n",
    "Repository_description =[]\n",
    "Contributors_counts =[]\n",
    "Language_used = []\n",
    "list1=[]\n",
    "contributors_counts=[]\n",
    "    \n",
    "# Scraping data from each url\n",
    "for url in urls1:\n",
    "    driver.get(url)    # Saving url                                                     \n",
    "    print(\"Scraping URL = \", url)\n",
    "    time.sleep(2)\n",
    "\n",
    "    try:\n",
    "        title = driver.find_elements_by_xpath(\"//*[@class='Box-row']//h1\")      \n",
    "        for i in title:\n",
    "            Repository_title.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Repository_title.append('-')\n",
    "    \n",
    "    try:\n",
    "        description = driver.find_elements_by_xpath(\"//p[@class='col-9 color-fg-muted my-1 pr-4']\")      # Extracting Brand from xpath\n",
    "        for i in description:\n",
    "            Repository_description.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Repository_description.append('-')\n",
    "    \n",
    "    try:\n",
    "        counts = driver.find_elements_by_xpath(\"//*[@class='octicon octicon-repo-forked']//..\")      # Extracting Brand from xpath\n",
    "        for i in counts:\n",
    "            Contributors_counts.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Contributors_counts.append('-')\n",
    "    \n",
    "    for j in range(0, len(Contributors_counts)):\n",
    "        if j%2:\n",
    "            list1.append(Contributors_counts[j])\n",
    "        else:\n",
    "            contributors_counts.append(Contributors_counts[j])\n",
    "\n",
    "    try:\n",
    "        language = driver.find_elements_by_xpath(\"//*[@class='Box-row']//div[2]//span//span[2]\")     \n",
    "        for i in language:\n",
    "            Language_used.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Language_used.append('-')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f7315a",
   "metadata": {},
   "source": [
    "Q6- Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https:/www.billboard.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "1. Song name\n",
    "2. Artist name\n",
    "3. Last week rank\n",
    "4. Peak rank\n",
    "5. Weeks on board\n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4823d60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.billboard.com/'  #Opening the billboards\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5) #delay for 5 seconds\n",
    "\n",
    "clk_charts = driver.find_element_by_xpath(\"/html/body/div[4]/header/div[1]/div/div/div[2]/div/nav/ul/li[1]/a\") \n",
    "clk_charts.click() #clicking the charts\n",
    "\n",
    "time.sleep(3) #delay for 3 seconds\n",
    "\n",
    "clk_100hot = driver.find_element_by_xpath(\"/html/body/div[4]/main/div[2]/div[1]/div[1]/div/div[1]/div[1]/div[2]/span/a\") \n",
    "clk_100hot.click() #clicking the 100hot button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a74f22b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song_Name</th>\n",
       "      <th>Artist_Name</th>\n",
       "      <th>Last_Week_Ranks</th>\n",
       "      <th>Peak_Ranks</th>\n",
       "      <th>Week_On_Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All I Want For Christmas Is You</td>\n",
       "      <td>Mariah Carey</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Easy On Me</td>\n",
       "      <td>Adele</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rockin' Around The Christmas Tree</td>\n",
       "      <td>Brenda Lee</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jingle Bell Rock</td>\n",
       "      <td>Bobby Helms</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Holly Jolly Christmas</td>\n",
       "      <td>Burl Ives</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Beers On Me</td>\n",
       "      <td>Dierks Bentley, Breland &amp; HARDY</td>\n",
       "      <td>-</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Already Dead</td>\n",
       "      <td>Juice WRLD</td>\n",
       "      <td>88</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>No Love</td>\n",
       "      <td>Summer Walker &amp; SZA</td>\n",
       "      <td>98</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>23</td>\n",
       "      <td>Sam Hunt</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Family Ties</td>\n",
       "      <td>Baby Keem &amp; Kendrick Lamar</td>\n",
       "      <td>100</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Song_Name                      Artist_Name  \\\n",
       "0     All I Want For Christmas Is You                     Mariah Carey   \n",
       "1                          Easy On Me                            Adele   \n",
       "2   Rockin' Around The Christmas Tree                       Brenda Lee   \n",
       "3                    Jingle Bell Rock                      Bobby Helms   \n",
       "4             A Holly Jolly Christmas                        Burl Ives   \n",
       "..                                ...                              ...   \n",
       "95                        Beers On Me  Dierks Bentley, Breland & HARDY   \n",
       "96                       Already Dead                       Juice WRLD   \n",
       "97                            No Love              Summer Walker & SZA   \n",
       "98                                 23                         Sam Hunt   \n",
       "99                        Family Ties       Baby Keem & Kendrick Lamar   \n",
       "\n",
       "   Last_Week_Ranks Peak_Ranks Week_On_Board  \n",
       "0                1          1            51  \n",
       "1                5          1            12  \n",
       "2                2          2            45  \n",
       "3                3          3            42  \n",
       "4                4          4            26  \n",
       "..             ...        ...           ...  \n",
       "95               -         96             1  \n",
       "96              88         20             6  \n",
       "97              98         13             8  \n",
       "98               -         99             1  \n",
       "99             100         18            18  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the empty list\n",
    "Song_name=[]\n",
    "Artist_name=[]\n",
    "Last_week_rank=[]\n",
    "Peak_rank=[]\n",
    "Week_on_board=[]\n",
    "\n",
    "try:   # Extracting song name from the xpath\n",
    "    song_name=driver.find_elements_by_xpath(\"//*[@class='lrv-u-width-100p']//ul//li//h3\")\n",
    "    for i in song_name:\n",
    "        Song_name.append(i.text)\n",
    "except:\n",
    "    Song_name.append('-')\n",
    "    \n",
    "try:   # Extracting artist name from the xpath\n",
    "    artist_name=driver.find_elements_by_xpath(\"//*[@class='lrv-u-width-100p']//ul//li[1]//span\")\n",
    "    for i in artist_name:\n",
    "        Artist_name.append(i.text)\n",
    "except:\n",
    "    Artist_name.append('-')\n",
    "\n",
    "try:   # Extracting last week rank from the xpath\n",
    "    Last_week_ranks=driver.find_elements_by_xpath(\"//*[@class='lrv-u-width-100p']//ul//li[4]//span\")\n",
    "    for i in Last_week_ranks:\n",
    "        Last_week_rank.append(i.text)\n",
    "except:\n",
    "    Last_week_rank.append('-')\n",
    "    \n",
    "lst=[]#rejection list\n",
    "last_week_ranks=[]#final list\n",
    "for i in range(0, len(Last_week_rank)): #extracting even and odd index details separately.\n",
    "    if i % 2:\n",
    "        lst.append(Last_week_rank[i])#rejecting odd index details\n",
    "    else :\n",
    "        last_week_ranks.append(Last_week_rank[i])#extracting even index details\n",
    "\n",
    "try:   # Extracting peak ranks from the xpath\n",
    "    peak_ranks=driver.find_elements_by_xpath(\"//*[@class='lrv-u-width-100p']//ul//li[5]//span\")\n",
    "    for i in peak_ranks:\n",
    "        Peak_rank.append(i.text)\n",
    "except:\n",
    "    Peak_rank.append('-')\n",
    "\n",
    "peak=[]#rejection list\n",
    "Peak_ranks=[]#final list\n",
    "\n",
    "for i in range(0, len(Peak_rank)):#extracting even and odd index details separately.\n",
    "    if i % 2:\n",
    "        peak.append(Peak_rank[i])#rejecting odd index details\n",
    "    else :\n",
    "        Peak_ranks.append(Peak_rank[i])#extracting even index details\n",
    "        \n",
    "try:   # Extracting week on boards from the xpath\n",
    "    Week_on_boards1=driver.find_elements_by_xpath(\"//*[@class='lrv-u-width-100p']//ul//li[6]//span\")\n",
    "    for i in Week_on_boards1:\n",
    "        Week_on_board.append(i.text)\n",
    "except:\n",
    "    Week_on_board.append('-')\n",
    "\n",
    "week=[]#rejection list\n",
    "Weeks_on_boards=[]#final list\n",
    "\n",
    "for i in range(0, len(Week_on_board)):#extracting even and odd index details separately.\n",
    "    if i % 2:\n",
    "        week.append(Week_on_board[i])#rejecting odd index details\n",
    "    else :\n",
    "        Weeks_on_boards.append(Week_on_board[i])#extracting even index details\n",
    "        \n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Song_Name':Song_name,\n",
    "                'Artist_Name':Artist_name,\n",
    "                'Last_Week_Ranks':last_week_ranks,\n",
    "                'Peak_Ranks': Peak_ranks,\n",
    "                'Week_On_Board': Week_on_board,\n",
    "                })\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b0973ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activating the chrome browser\n",
    "PATH = 'C:/Users/hp-pc/Downloads/chromedriver_win32/chromedriver'\n",
    "driver = webdriver.Chrome(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b81f258",
   "metadata": {},
   "source": [
    "7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "\n",
    "You have to find the following details:\n",
    "1. Name\n",
    "2. Designation\n",
    "3. Company\n",
    "4. Skills they hire for\n",
    "5. Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "91161386",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/mnjuser/homepage'  #Opening the naukri.com\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5) #time delay of 5 seconds\n",
    "\n",
    "try: #close the pop up by clicking 'Later' option\n",
    "    clk_later = driver.find_element_by_xpath(\"//span[@id='block']\") \n",
    "    clk_later.click() \n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "\n",
    "time.sleep(2)#time delay of 2 seconds\n",
    "\n",
    "clk_recruiters = driver.find_element_by_xpath(\"//div[text()='Recruiters' and @class='mTxt']\") \n",
    "clk_recruiters.click() #click the option 'recruiters'\n",
    "\n",
    "time.sleep(6)#time delay of 6 seconds\n",
    "\n",
    "handles = driver.window_handles #returns all the handles value of opened browser\n",
    "for handle in handles:\n",
    "    driver.switch_to.window(handle)#switch to second window\n",
    "    if driver.title==\"HR Manager - HR Executive - HR Recruiter Consultants - Naukri.com\":\n",
    "        search_des=driver.find_element_by_xpath(\"//input[@class='sugInp']\")\n",
    "        search_des.clear()\n",
    "        search_des.send_keys('Data Science')#send keys to search bar\n",
    "        \n",
    "        time.sleep(5)\n",
    "        \n",
    "        clk_search = driver.find_element_by_xpath(\"//button[@id='qsbFormBtn']\")\n",
    "        clk_search.click()#clicking on search bar button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "01419b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Analytics, Business Intelligence, Business Ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>Machine Learning, algorithms, Go Getter, Compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Technical Training, Software Development, Pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Software Development, It Sales, Account Manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Priyanka Akiri</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Infinitive Software Solutions</td>\n",
       "      <td>Oracle Dba, Data Science, Data Warehousing, ET...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>Qa, Ui/ux, Java Developer, Java Architect, C++...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>Business Intelligence, Data Warehousing, Data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td>Office Administration, Hr Administration, tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>SocialPrachar.com</td>\n",
       "      <td>Social Media, digital media maketing, seo, smm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sakshi Chhikara</td>\n",
       "      <td>Assistant Manager HR</td>\n",
       "      <td>BIZ INFOTECNO PRIVATE LIMITED</td>\n",
       "      <td>React.js, Data Science, Java, Front End, Busin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>BISP Solutions</td>\n",
       "      <td>Big Data, Hadoop, Data Analytics, Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>Bristlecone India Ltd</td>\n",
       "      <td>Qlikview, Qlik Sense, Microsoft Azure, Power B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Compumatrice Multimedia Pvt Ltd</td>\n",
       "      <td>Big Data, Data Science, Artificial Intelligenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Easi Tax</td>\n",
       "      <td>Telecalling, Client Interaction, Marketing, Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>Novelworx Digital Solutions</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>AXESTRACK SOFTWARE SOLUTIONS PRIVATE...</td>\n",
       "      <td>Corporate Sales, Software Development, Softwar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>FirstTech Consaltants Pvt.Ltd</td>\n",
       "      <td>Data Analytics, Data Science, Machine Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>Data Science, Machine Learning, Python, R, Dee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Shaun Rao</td>\n",
       "      <td>Manager Human Resources</td>\n",
       "      <td>Exela Technologies</td>\n",
       "      <td>Java, Net, Angularjs, Hr, Infrastructure, Mana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Azahar Shaikh</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>NEAL ANALYTICS SERVICES PVT LTD</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Manas</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>Autumn Leaf Consulting Services Private...</td>\n",
       "      <td>Software Architecture, Vp Engineering, Product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>kumar</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>trainin</td>\n",
       "      <td>Data Science, Hadoop, Rpas, Devops, Python, Aw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sunil Vedula</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Nanoprecise Sci Corp</td>\n",
       "      <td>Signal Processing, Machine Learning, Neural Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Rajat Kumar</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>R.S Consultancy &amp;amp; Services</td>\n",
       "      <td>Web Technologies, Project Management, Software...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Avodha</td>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>Nikitha Palaparthi</td>\n",
       "      <td>Ethical Hacking, Security Operations Center, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Dollarbird Information Services Pvt, Ltd</td>\n",
       "      <td>Data Analytics, Managed Services, Team Leading...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Priya Khare</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>Independent Consultant</td>\n",
       "      <td>Data Science, Artificial Intelligence, analyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Dhruv Dev Dubey</td>\n",
       "      <td>Company Recruitment Head</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Server Administartion, Verilog, Vhdl, Digital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>ASCO consulting</td>\n",
       "      <td>Machine Learning, Artificial Intelligence, Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Kanan</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>NY INST</td>\n",
       "      <td>C, C++, Artificial Intelligence, Python, Php, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Shashikant Chaudhary</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>3D India Staffing Research &amp;amp; Consulting...</td>\n",
       "      <td>Relationship Management, Retail Sales, Private...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Brad</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>O.C. Tanner</td>\n",
       "      <td>Data Science, Software Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Rutuja Pawar</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Demand Matrix</td>\n",
       "      <td>Data Science, Big Data Analytics, Digital Mark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Madhusudhan Sridhar</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>MADHUSUDHAN SRIDHAR</td>\n",
       "      <td>Data Science, Recruitment, Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Ankit Sinha</td>\n",
       "      <td>Head Analytics</td>\n",
       "      <td>Suntech Global</td>\n",
       "      <td>B.Tech, Tableau, Statistics, R, Analytics, Tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Gaurav Chouhan</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>Strategic Consulting Lab</td>\n",
       "      <td>Software Development, Business Intelligence, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Rashi Kacker</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Impel Labs Pvt. Ltd.</td>\n",
       "      <td>Data Science, Node.js, Angularjs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ashwini</td>\n",
       "      <td>Director Global Delivery</td>\n",
       "      <td>MRP Advisers</td>\n",
       "      <td>Data Science, Media Marketing, Resource Planni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>Co Founder</td>\n",
       "      <td>Saras Solutions India Pvt Ltd</td>\n",
       "      <td>Data Analysis, Learning, Data Science, Compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>WildJasmine</td>\n",
       "      <td>Java, Hadoop, R, Machine Learning, Spark, Flum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>LNT Private Limited</td>\n",
       "      <td>Software Development, Core Java, Unit Testing,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Amir Chowdhury</td>\n",
       "      <td>Managing Partner</td>\n",
       "      <td>Granular.ai</td>\n",
       "      <td>Machine Learning, Data Science, Product Manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SREEDHAR</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Data Science, Machine Learning, Big Data Analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Radha Manivasagam</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Techcovery</td>\n",
       "      <td>Python, Artificial Intelligence, Machine Learn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name  \\\n",
       "0                                    Aakash Harit   \n",
       "1                            shravan Kumar Gaddam   \n",
       "2                        MARSIAN Technologies LLP   \n",
       "3                                    Anik Agrawal   \n",
       "4                                    subhas patel   \n",
       "5    Abhishek - Only Analytics Hiring - India and   \n",
       "6   Institute for Financial Management and Resear   \n",
       "7                                     Balu Ramesh   \n",
       "8                                   Asif Lucknowi   \n",
       "9                                 InstaFinancials   \n",
       "10                                 Priyanka Akiri   \n",
       "11                                Kalpana Dumpala   \n",
       "12                                        Mubarak   \n",
       "13                                 Kushal Rastogi   \n",
       "14                             Mahesh Babu Channa   \n",
       "15                                Sakshi Chhikara   \n",
       "16                                   Kapil Devang   \n",
       "17                                    Ruchi Dhote   \n",
       "18                             Sandhya Khandagale   \n",
       "19                                  Manisha Yadav   \n",
       "20                                    Riya Rajesh   \n",
       "21                           Rashmi Bhattacharjee   \n",
       "22                                  Faizan Kareem   \n",
       "23                                 Rithika dadwal   \n",
       "24                                      Shaun Rao   \n",
       "25                                  Azahar Shaikh   \n",
       "26                                          Manas   \n",
       "27                                          kumar   \n",
       "28                                   Sunil Vedula   \n",
       "29                                    Rajat Kumar   \n",
       "30                                         Avodha   \n",
       "31                                      Jayanth N   \n",
       "32                                    Priya Khare   \n",
       "33                                Dhruv Dev Dubey   \n",
       "34                                    Amit Sharma   \n",
       "35                                          Kanan   \n",
       "36                           Shashikant Chaudhary   \n",
       "37                                           Brad   \n",
       "38                                   Rutuja Pawar   \n",
       "39                            Madhusudhan Sridhar   \n",
       "40                                    Ankit Sinha   \n",
       "41                                 Gaurav Chouhan   \n",
       "42                                   Rashi Kacker   \n",
       "43                                        Ashwini   \n",
       "44                                   Balaji Kolli   \n",
       "45                                 Rajani Nagaraj   \n",
       "46                                    ROHIT Kumar   \n",
       "47                                 Amir Chowdhury   \n",
       "48                                       SREEDHAR   \n",
       "49                              Radha Manivasagam   \n",
       "\n",
       "                            Designation  \\\n",
       "0                            HR Manager   \n",
       "1                     Company Recruiter   \n",
       "2                            Company HR   \n",
       "3                     Company Recruiter   \n",
       "4                           Founder CEO   \n",
       "5           Recruitment Lead Consultant   \n",
       "6                     Programme Manager   \n",
       "7                      HR Administrator   \n",
       "8                              Director   \n",
       "9                        Human Resource   \n",
       "10                           HR Manager   \n",
       "11                     Executive Hiring   \n",
       "12                           Company HR   \n",
       "13                           Company HR   \n",
       "14                         HR Team Lead   \n",
       "15                 Assistant Manager HR   \n",
       "16                           HR Manager   \n",
       "17  Senior Executive Talent Acquisition   \n",
       "18                         HR Recruiter   \n",
       "19                         HR Executive   \n",
       "20           Manager Talent Acquisition   \n",
       "21                              HR Head   \n",
       "22                           HR MANAGER   \n",
       "23                         HR Recruiter   \n",
       "24              Manager Human Resources   \n",
       "25                    Company Recruiter   \n",
       "26              Lead Talent acquisition   \n",
       "27                           Proprietor   \n",
       "28                                  CEO   \n",
       "29                          Founder CEO   \n",
       "30       Business Development Associate   \n",
       "31                      Project Manager   \n",
       "32                       Senior Manager   \n",
       "33             Company Recruitment Head   \n",
       "34                           Consultant   \n",
       "35         senior technology instructor   \n",
       "36             HR Recruiter/HR Excutive   \n",
       "37        Manager, Technical Recruiting   \n",
       "38                  Technical Recruiter   \n",
       "39                      Erp Implementer   \n",
       "40                       Head Analytics   \n",
       "41              Chief Technical Officer   \n",
       "42                   Sr Product Manager   \n",
       "43             Director Global Delivery   \n",
       "44                           Co Founder   \n",
       "45                           HR Manager   \n",
       "46                            Architect   \n",
       "47                     Managing Partner   \n",
       "48               Recruitment Consultant   \n",
       "49                         HR Executive   \n",
       "\n",
       "                                           Company  \\\n",
       "0                             Data Science Network   \n",
       "1                    Shore Infotech India Pvt. Ltd   \n",
       "2                         MARSIAN Technologies LLP   \n",
       "3            Enerlytics Software Solutions Pvt Ltd   \n",
       "4                                  LibraryXProject   \n",
       "5       Apidel Technologies Division of Transpower   \n",
       "6                                             IFMR   \n",
       "7                      Techvantage Systems Pvt Ltd   \n",
       "8                       Weupskill- Live Wire India   \n",
       "9                 CBL Data Science Private Limited   \n",
       "10                   Infinitive Software Solutions   \n",
       "11                              Innominds Software   \n",
       "12                                        MoneyTap   \n",
       "13              QuantMagnum Technologies Pvt. Ltd.   \n",
       "14                               SocialPrachar.com   \n",
       "15                   BIZ INFOTECNO PRIVATE LIMITED   \n",
       "16                                  BISP Solutions   \n",
       "17                           Bristlecone India Ltd   \n",
       "18                 Compumatrice Multimedia Pvt Ltd   \n",
       "19                                        Easi Tax   \n",
       "20                     Novelworx Digital Solutions   \n",
       "21         AXESTRACK SOFTWARE SOLUTIONS PRIVATE...   \n",
       "22                   FirstTech Consaltants Pvt.Ltd   \n",
       "23                                Affine Analytics   \n",
       "24                              Exela Technologies   \n",
       "25                 NEAL ANALYTICS SERVICES PVT LTD   \n",
       "26      Autumn Leaf Consulting Services Private...   \n",
       "27                                         trainin   \n",
       "28                            Nanoprecise Sci Corp   \n",
       "29                  R.S Consultancy &amp; Services   \n",
       "30                              Nikitha Palaparthi   \n",
       "31        Dollarbird Information Services Pvt, Ltd   \n",
       "32                          Independent Consultant   \n",
       "33                                    Confidential   \n",
       "34                                 ASCO consulting   \n",
       "35                                         NY INST   \n",
       "36  3D India Staffing Research &amp; Consulting...   \n",
       "37                                     O.C. Tanner   \n",
       "38                                   Demand Matrix   \n",
       "39                             MADHUSUDHAN SRIDHAR   \n",
       "40                                  Suntech Global   \n",
       "41                        Strategic Consulting Lab   \n",
       "42                            Impel Labs Pvt. Ltd.   \n",
       "43                                    MRP Advisers   \n",
       "44                   Saras Solutions India Pvt Ltd   \n",
       "45                                     WildJasmine   \n",
       "46                             LNT Private Limited   \n",
       "47                                     Granular.ai   \n",
       "48     JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED   \n",
       "49                                      Techcovery   \n",
       "\n",
       "                                               Skills  \n",
       "0   Classic ASP Developer, Internet Marketing Prof...  \n",
       "1   .Net, Java, Data Science, Linux Administration...  \n",
       "2   Data Science, Artificial Intelligence, Machine...  \n",
       "3   Mean Stack, javascript, angularjs, mongodb, We...  \n",
       "4   Hadoop, Spark, Digital Strategy, Data Architec...  \n",
       "5   Analytics, Business Intelligence, Business Ana...  \n",
       "6                                        Data Science  \n",
       "7   Machine Learning, algorithms, Go Getter, Compu...  \n",
       "8   Technical Training, Software Development, Pres...  \n",
       "9   Software Development, It Sales, Account Manage...  \n",
       "10  Oracle Dba, Data Science, Data Warehousing, ET...  \n",
       "11  Qa, Ui/ux, Java Developer, Java Architect, C++...  \n",
       "12  Business Intelligence, Data Warehousing, Data ...  \n",
       "13  Office Administration, Hr Administration, tele...  \n",
       "14  Social Media, digital media maketing, seo, smm...  \n",
       "15  React.js, Data Science, Java, Front End, Busin...  \n",
       "16     Big Data, Hadoop, Data Analytics, Data Science  \n",
       "17  Qlikview, Qlik Sense, Microsoft Azure, Power B...  \n",
       "18  Big Data, Data Science, Artificial Intelligenc...  \n",
       "19  Telecalling, Client Interaction, Marketing, Re...  \n",
       "20                                       Data Science  \n",
       "21  Corporate Sales, Software Development, Softwar...  \n",
       "22  Data Analytics, Data Science, Machine Learning...  \n",
       "23  Data Science, Machine Learning, Python, R, Dee...  \n",
       "24  Java, Net, Angularjs, Hr, Infrastructure, Mana...  \n",
       "25  Data Science, Artificial Intelligence, Machine...  \n",
       "26  Software Architecture, Vp Engineering, Product...  \n",
       "27  Data Science, Hadoop, Rpas, Devops, Python, Aw...  \n",
       "28  Signal Processing, Machine Learning, Neural Ne...  \n",
       "29  Web Technologies, Project Management, Software...  \n",
       "30  Ethical Hacking, Security Operations Center, S...  \n",
       "31  Data Analytics, Managed Services, Team Leading...  \n",
       "32  Data Science, Artificial Intelligence, analyti...  \n",
       "33  Server Administartion, Verilog, Vhdl, Digital ...  \n",
       "34  Machine Learning, Artificial Intelligence, Dat...  \n",
       "35  C, C++, Artificial Intelligence, Python, Php, ...  \n",
       "36  Relationship Management, Retail Sales, Private...  \n",
       "37                 Data Science, Software Engineering  \n",
       "38  Data Science, Big Data Analytics, Digital Mark...  \n",
       "39                  Data Science, Recruitment, Salary  \n",
       "40  B.Tech, Tableau, Statistics, R, Analytics, Tim...  \n",
       "41  Software Development, Business Intelligence, B...  \n",
       "42                   Data Science, Node.js, Angularjs  \n",
       "43  Data Science, Media Marketing, Resource Planni...  \n",
       "44  Data Analysis, Learning, Data Science, Compute...  \n",
       "45  Java, Hadoop, R, Machine Learning, Spark, Flum...  \n",
       "46  Software Development, Core Java, Unit Testing,...  \n",
       "47  Machine Learning, Data Science, Product Manage...  \n",
       "48  Data Science, Machine Learning, Big Data Analy...  \n",
       "49  Python, Artificial Intelligence, Machine Learn...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list\n",
    "Name=[]\n",
    "Designation=[]\n",
    "Company=[]\n",
    "Skills=[]\n",
    "Location=[]\n",
    "try:   #Extracting name from the xpath\n",
    "    name=driver.find_elements_by_xpath(\"//*[@class='fl ellipsis']\")\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except:\n",
    "    Name.append('-')\n",
    "\n",
    "time.sleep(4) #delay for 4 seconds\n",
    "\n",
    "try:   #Extracting designation from the xpath\n",
    "    designation=driver.find_elements_by_xpath(\"//*[@class='ellipsis clr']\")\n",
    "    for i in designation:\n",
    "        Designation.append(i.text)\n",
    "except:\n",
    "    Designation.append('-')\n",
    "\n",
    "time.sleep(4) #delay for 4 seconds\n",
    "\n",
    "try:   #Extracting company from the xpath\n",
    "    company=driver.find_elements_by_xpath(\"//*[@class='ellipsis']//..//a[2]\")\n",
    "    for i in company:\n",
    "        Company.append(i.text)\n",
    "except:\n",
    "    Company.append('-')\n",
    "\n",
    "time.sleep(4) #delay for 4 seconds\n",
    "\n",
    "\n",
    "try:   #Extracting skills from the xpath\n",
    "    skills=driver.find_elements_by_xpath(\"//*[@class='hireSec highlightable']\")\n",
    "    for i in skills:\n",
    "        Skills.append(i.text)\n",
    "except:\n",
    "    Skills.append('-')\n",
    "\n",
    "\n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Name':Name,\n",
    "                'Designation':Designation,\n",
    "                'Company':Company,\n",
    "                'Skills': Skills,\n",
    "                })\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85df6c9",
   "metadata": {},
   "source": [
    "Q8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare/\n",
    "\n",
    "You have to find the following details:\n",
    "1. Book name\n",
    "2. Author name\n",
    "3. Volumes sold\n",
    "4. Publisher\n",
    "5. Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "60e3d55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_Name</th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>Volumes_Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book_Name       Author_Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes_Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'  #Open the website by using driver.get\n",
    "driver.get(url) #opening the guardian.com\n",
    "\n",
    "time.sleep(5) #delay for 5 seconds\n",
    "#Creating Empty list\n",
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "try:   #Extracting week on book name from the xpath\n",
    "    book_name=driver.find_elements_by_xpath(\"//*[@class='in-article sortable']//tbody//tr//td[2]\")\n",
    "    for i in book_name:\n",
    "        Book_name.append(i.text)\n",
    "except:\n",
    "    Book_name.append('-')\n",
    "\n",
    "time.sleep(4) #delay for 4 seconds\n",
    "        \n",
    "try:   # Extracting week on author name from the xpath\n",
    "    author_name=driver.find_elements_by_xpath(\"//*[@class='in-article sortable']//tbody//tr//td[3]\")\n",
    "    for i in author_name:\n",
    "        Author_name.append(i.text)\n",
    "except:\n",
    "    Author_name.append('-') \n",
    "\n",
    "time.sleep(4) #delay for 4 seconds\n",
    "\n",
    "try:   # Extracting volumes sold from the xpath\n",
    "    vol_sold=driver.find_elements_by_xpath(\"//*[@class='in-article sortable']//tbody//tr//td[4]\")\n",
    "    for i in vol_sold:\n",
    "        Volumes_sold.append(i.text)\n",
    "except:\n",
    "    Volumes_sold.append('-') \n",
    "\n",
    "time.sleep(4) #delay for 4 seconds\n",
    "\n",
    "try:   # Extracting publisher from the xpath\n",
    "    publisher=driver.find_elements_by_xpath(\"//*[@class='in-article sortable']//tbody//tr//td[5]\")\n",
    "    for i in publisher:\n",
    "        Publisher.append(i.text)\n",
    "except:\n",
    "    Publisher.append('-')\n",
    "\n",
    "time.sleep(4) #delay for 4 seconds\n",
    "\n",
    "try:   # Extracting genre from the xpath\n",
    "    genre=driver.find_elements_by_xpath(\"//*[@class='in-article sortable']//tbody//tr//td[6]\")\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except:\n",
    "    Genre.append('-')\n",
    "\n",
    "time.sleep(4) #delay for 4 seconds\n",
    "\n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Book_Name':Book_name,\n",
    "                'Author_Name':Author_name,\n",
    "                'Volumes_Sold':Volumes_sold,\n",
    "                'Publisher': Publisher,\n",
    "                'Genre': Genre,\n",
    "                })\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c39e19",
   "metadata": {},
   "source": [
    "Q9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "\n",
    "You have to find the following details:\n",
    "1. Name\n",
    "2. Year span\n",
    "3. Genre\n",
    "4. Run time\n",
    "5. Ratings\n",
    "6. Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4c3886b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year_span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run_time</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>1,930,637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>951,515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>922,206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>276,325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>236,572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>47,179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>57,975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>183,043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>38,331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>218,022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year_span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run_time      Votes  \n",
       "0    57 min  1,930,637  \n",
       "1    51 min    951,515  \n",
       "2    44 min    922,206  \n",
       "3    60 min    276,325  \n",
       "4    43 min    236,572  \n",
       "..      ...        ...  \n",
       "95   42 min     47,179  \n",
       "96   50 min     57,975  \n",
       "97   42 min    183,043  \n",
       "98   45 min     38,331  \n",
       "99  572 min    218,022  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.imdb.com/list/ls095964455/'  \n",
    "driver.get(url)# opening the imdb.com\n",
    "\n",
    "time.sleep(4)#delay for 4 seconds\n",
    "\n",
    "#Creating Empty List\n",
    "Name=[]\n",
    "Year_span=[]\n",
    "Genre=[]\n",
    "Run_time=[]\n",
    "Ratings=[]\n",
    "Votes=[]\n",
    "\n",
    "try:   # Extracting name from the xpath\n",
    "    name=driver.find_elements_by_xpath(\"//*[@class='lister-item-header']//a\")\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except:\n",
    "    Name.append('-')\n",
    "    \n",
    "try:   # Extracting year span from the xpath\n",
    "    year=driver.find_elements_by_xpath(\"//*[@class='lister-item-header']//span[2]\")\n",
    "    for i in year:\n",
    "        Year_span.append(i.text)\n",
    "except:\n",
    "    Year_span.append('-')\n",
    "    \n",
    "try:  # Extracting genre from the xpath\n",
    "    genre=driver.find_elements_by_xpath(\"//*[@class='genre']\")\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except:\n",
    "    Genre.append('-')\n",
    "    \n",
    "try:   # Extracting run time from the xpath\n",
    "    run_time=driver.find_elements_by_xpath(\"//span[@class='runtime']\")\n",
    "    for i in run_time:\n",
    "        Run_time.append(i.text)\n",
    "except:\n",
    "    Run_time.append('-')\n",
    "    \n",
    "try:   # Extracting ratings from the xpath\n",
    "    ratings=driver.find_elements_by_xpath(\"/html/body/div[3]/div/div[2]/div[3]/div[1]/div/div[3]/div[3]/div/div[2]/div[1]/div[1]/span[2]\")\n",
    "    for i in ratings:\n",
    "        Ratings.append(i.text)\n",
    "except:\n",
    "    Ratings.append('-')\n",
    "    \n",
    "try:   # Extracting votes from the xpath\n",
    "    votes=driver.find_elements_by_xpath(\"//*[@name='nv']\")\n",
    "    for i in votes:\n",
    "        Votes.append(i.text)\n",
    "except:\n",
    "    Votes.append('-')\n",
    "    \n",
    "    \n",
    "time.sleep(4) #delay for 4 seconds\n",
    "\n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Name':Name,\n",
    "                'Year_span':Year_span,\n",
    "                'Genre':Genre,\n",
    "                'Run_time': Run_time,\n",
    "                'Votes': Votes,\n",
    "                })\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b506d03",
   "metadata": {},
   "source": [
    "Q10. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "\n",
    "You have to find the following details:\n",
    "1. Dataset name\n",
    "2. Data type\n",
    "3. Task\n",
    "4. Attribute type\n",
    "5. No of instances\n",
    "6. No of attribute\n",
    "7. Year\n",
    "\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "093ced1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset_name</th>\n",
       "      <th>Data_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>No_of_instances</th>\n",
       "      <th>No_of_attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset_name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data_type                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute_type No_of_instances No_of_attribute   Year  \n",
       "0    Categorical, Integer, Real            4177               8   1995   \n",
       "1          Categorical, Integer           48842              14   1996   \n",
       "2    Categorical, Integer, Real             798              38          \n",
       "3                   Categorical           37711             294   1998   \n",
       "4    Categorical, Integer, Real             452             279   1998   \n",
       "..                           ...             ...             ...    ...  \n",
       "617               Integer, Real           75840             525   2020   \n",
       "618               Integer, Real             400              50   2020   \n",
       "619                                        1014               7   2020   \n",
       "620                        Real           10129              16   2021   \n",
       "621                        Real            4000               2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://archive.ics.uci.edu/ml/datasets.php'  \n",
    "driver.get(url)#opening the archive.ics.uci.edu\n",
    "\n",
    "#Creating Empty List\n",
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_of_instances=[]\n",
    "No_of_attribute=[]\n",
    "Year=[]\n",
    "\n",
    "try:   # Extracting Dataset_name from the xpath\n",
    "    name=driver.find_elements_by_xpath(\"/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[1]/table/tbody/tr/td[2]/p\")\n",
    "    for i in name:\n",
    "        Dataset_name.append(i.text)\n",
    "except:\n",
    "    Dataset_name.append('-')\n",
    "try:   # Extracting Data_type from the xpath\n",
    "    type=driver.find_elements_by_xpath(\"//p[@class='normal']//..//..//..//tbody//..//..//..//td[2]\")\n",
    "    for i in type:\n",
    "        Data_type.append(i.text)\n",
    "except:\n",
    "    Data_type.append('-')\n",
    "    \n",
    "list2=[]#rejection list\n",
    "data_type=[]#final list\n",
    "\n",
    "for j in range(0, len(Data_type)):#extracting only even and odd index details\n",
    "    if j%2:\n",
    "        data_type.append(Data_type[j])#odd index details are useful \n",
    "    else:\n",
    "        list2.append(Data_type[j])#rejecting even index details\n",
    "        \n",
    "try:   # Extracting task from the xpath\n",
    "    task=driver.find_elements_by_xpath(\"//p[@class='normal']//..//..//..//tbody//..//..//..//td[3]\")\n",
    "    for i in task:\n",
    "        Task.append(i.text)\n",
    "except:\n",
    "    Task.append('-')\n",
    "    \n",
    "try:   # Extracting Attribute_type from the xpath\n",
    "    attribute=driver.find_elements_by_xpath(\"//p[@class='normal']//..//..//..//tbody//..//..//..//td[4]\")\n",
    "    for i in attribute:\n",
    "        Attribute_type.append(i.text)\n",
    "except:\n",
    "    Attribute_type.append('-')\n",
    "    \n",
    "try:   # Extracting No_of_instances from the xpath\n",
    "    instances=driver.find_elements_by_xpath(\"//p[@class='normal']//..//..//..//tbody//..//..//..//td[5]\")\n",
    "    for i in instances:\n",
    "        No_of_instances.append(i.text)\n",
    "except:\n",
    "    No_of_instances.append('-')\n",
    "    \n",
    "    \n",
    "try:   # Extracting No_of_attribute from the xpath\n",
    "    attribute1=driver.find_elements_by_xpath(\"//p[@class='normal']//..//..//..//tbody//..//..//..//td[6]\")\n",
    "    for i in attribute1:\n",
    "        No_of_attribute.append(i.text)\n",
    "except:\n",
    "    No_of_attribute.append('-')\n",
    "    \n",
    "    \n",
    "try:   # Extracting Year from the xpath\n",
    "    year=driver.find_elements_by_xpath(\"//p[@class='normal']//..//..//..//tbody//..//..//..//td[7]\")\n",
    "    for i in year:\n",
    "        Year.append(i.text)\n",
    "except:\n",
    "    Year.append('-')\n",
    "\n",
    "time.sleep(4)#delay for 4 seconds\n",
    "\n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Dataset_name':Dataset_name,\n",
    "                'Data_type':data_type,\n",
    "                'Task':Task,\n",
    "                'Attribute_type': Attribute_type,\n",
    "                'No_of_instances': No_of_instances,\n",
    "                 'No_of_attribute': No_of_attribute,\n",
    "                 'Year': Year,\n",
    "                })\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3890cd51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
